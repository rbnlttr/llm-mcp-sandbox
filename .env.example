# Optional: Anthropic API Key f√ºr Cloud-LLM
ANTHROPIC_API_KEY=

# Lokales LLM verwenden (true/false)
USE_LOCAL_LLM=true

# Lokales Modell (llama3.2, mistral, codellama, etc.)
LOCAL_MODEL=llama3.2
